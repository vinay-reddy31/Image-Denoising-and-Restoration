# -*- coding: utf-8 -*-
"""SRCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-3Xnbx-LkGc2W2lGCzgz58BVz9G5kcrG
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar10
from skimage.transform import resize

# Load CIFAR-10 dataset
(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()

# Use a subset of the dataset for quicker execution


import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar10
from skimage.transform import resize

# Load CIFAR-10 dataset
(X_train, _), (X_test, _) = cifar10.load_data()

# Normalize images
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

# Create low-resolution images by downscaling and upscaling

# Train the model with callbacks for better optimization

X_train = X_train[:1000]
X_test = X_test[:100]
Y_train = Y_train[:1000]
Y_test = Y_test[:100]

def create_lr_images(images, scale_factor=3):
    lr_images = np.zeros(images.shape)
    for i in range(images.shape[0]):
        lr_img = resize(images[i],
                        (images.shape[1] // scale_factor, images.shape[2] // scale_factor),
                        anti_aliasing=True)
        lr_img = resize(lr_img, (images.shape[1], images.shape[2]), anti_aliasing=True)
        lr_images[i] = lr_img
    return lr_images

X_train_lr = create_lr_images(X_train)
X_test_lr = create_lr_images(X_test)

# Build the SRCNN model
def build_srcnn(input_shape=(32, 32, 3)):
    model = Sequential()
    model.add(Conv2D(64, (9, 9), activation='relu', padding='same', input_shape=input_shape))
    model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))
    model.add(Conv2D(3, (5, 5), activation='linear', padding='same'))
    return model

srcnn = build_srcnn()
srcnn.summary()

# Compile the model
srcnn.compile(optimizer=Adam(learning_rate=0.0003), loss=MeanSquaredError())

callbacks = [
    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),
    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)
]

# Train the model
srcnn.fit(X_train_lr, X_train, epochs=20, batch_size=32, validation_split=0.2, callbacks=callbacks)

# Evaluate the model
loss = srcnn.evaluate(X_test_lr, X_test)
print(f"Test Loss: {loss}")

# Function to predict and show images
def predict_and_show(model, lr_img, hr_img):
    pred = model.predict(np.expand_dims(lr_img, axis=0))
    pred = np.squeeze(pred, axis=0)

    plt.figure(figsize=(15, 5))
    plt.subplot(1, 3, 1)
    plt.title('Low Resolution')
    plt.imshow(lr_img)
    plt.subplot(1, 3, 2)
    plt.title('SRCNN Prediction')
    plt.imshow(pred)
    plt.subplot(1, 3, 3)
    plt.title('High Resolution')
    plt.imshow(hr_img)
    plt.show()

# Show predictions on test images
for i in range(5):
    predict_and_show(srcnn, X_test_lr[i], X_test[i])

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar10
from skimage.transform import resize
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
import torch
import lpips
from tqdm import tqdm
import time

# Calculate PSNR
def calculate_psnr(original, generated):
    return psnr(original, generated)

# Calculate SSIM
def calculate_ssim(original, generated):
    return ssim(original, generated, multichannel=True)

# Calculate LPIPS using PyTorch
def calculate_lpips(original, generated):
    loss_fn = lpips.LPIPS(net='vgg')
    original_torch = torch.tensor(original.transpose(2, 0, 1)).unsqueeze(0).float()
    generated_torch = torch.tensor(generated.transpose(2, 0, 1)).unsqueeze(0).float()
    lpips_value = loss_fn(original_torch, generated_torch)
    return lpips_value.item()

# Assuming X_test_lr and X_test are your test data and srcnn is your model
psnr_values = []
ssim_values = []
lpips_values = []

start_time = time.time()

for i in tqdm(range(len(X_test_lr)), desc="Processing images"):
    lr_img = X_test_lr[i]
    hr_img = X_test[i]
    sr_img = srcnn.predict(np.expand_dims(lr_img, axis=0))[0]

    psnr_value = calculate_psnr(hr_img, sr_img)
    ssim_value = calculate_ssim(hr_img, sr_img)
    lpips_value = calculate_lpips(hr_img, sr_img)

    psnr_values.append(psnr_value)
    ssim_values.append(ssim_value)
    lpips_values.append(lpips_value)

# Calculate total time taken
end_time = time.time()
total_time = end_time - start_time

# Calculate average metrics
avg_psnr = np.mean(psnr_values)
avg_ssim = np.mean(ssim_values)
avg_lpips = np.mean(lpips_values)

print(f"Average PSNR: {avg_psnr}")
print(f"Average SSIM: {avg_ssim}")
print(f"Average LPIPS: {avg_lpips}")
print(f"Total time taken: {total_time} seconds")